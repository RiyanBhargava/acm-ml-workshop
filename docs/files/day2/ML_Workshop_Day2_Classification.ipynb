{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1ETKD1wDwC_"
      },
      "outputs": [],
      "source": [
        "#Importing necesssary Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ukr7yVChEbur"
      },
      "outputs": [],
      "source": [
        "#Importing all required models\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeN04fLRErhZ"
      },
      "outputs": [],
      "source": [
        "#Uploading the dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFuxfGKIE7VT"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('preprocessed_data.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQhkm2LQFEdu"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XO8UGkbpFFpy"
      },
      "outputs": [],
      "source": [
        "feature_cols = [col for col in df.columns if col != 'Drug']\n",
        "X = df[feature_cols]\n",
        "y = df['Drug']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt-7aWqZFOs0"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# SECTION 3: TRAIN-TEST SPLIT & SCALING\n",
        "# ===================================================\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juxyAhKmFb54"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# SECTION 4: CLASSIFICATION MODELS\n",
        "# ===================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 4: TRAINING CLASSIFICATION MODELS\")\n",
        "print(\"=\"*80)\n",
        "print(\"Target: Predict categorical class labels\")\n",
        "print(\"-\"*80)\n",
        "\n",
        "classification_results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iVJw7Ln3Fk3J"
      },
      "outputs": [],
      "source": [
        "# 1. LOGISTIC REGRESSION\n",
        "print(\"\\n1. Logistic Regression\")\n",
        "print(\"-\"*40)\n",
        "lr = LogisticRegression(max_iter=1000)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "classification_results['Logistic Regression'] = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_lr),\n",
        "    'Precision': precision_score(y_test, y_pred_lr, average='weighted'),\n",
        "    'Recall': recall_score(y_test, y_pred_lr, average='weighted'),\n",
        "    'F1 Score': f1_score(y_test, y_pred_lr, average='weighted')\n",
        "}\n",
        "\n",
        "print(classification_report(y_test, y_pred_lr))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7jXsbXwGWtm"
      },
      "outputs": [],
      "source": [
        "# 2. DECISION TREE CLASSIFIER\n",
        "print(\"\\n2. Decision Tree Classifier\")\n",
        "print(\"-\"*40)\n",
        "dt = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "\n",
        "classification_results['Decision Tree'] = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_dt),\n",
        "    'Precision': precision_score(y_test, y_pred_dt, average='weighted'),\n",
        "    'Recall': recall_score(y_test, y_pred_dt, average='weighted'),\n",
        "    'F1 Score': f1_score(y_test, y_pred_dt, average='weighted')\n",
        "}\n",
        "\n",
        "print(classification_report(y_test, y_pred_dt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z96Sbxx7GYYL"
      },
      "outputs": [],
      "source": [
        "# 3. RANDOM FOREST CLASSIFIER\n",
        "print(\"\\n3. Random Forest Classifier\")\n",
        "print(\"-\"*40)\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "\n",
        "classification_results['Random Forest'] = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_rf),\n",
        "    'Precision': precision_score(y_test, y_pred_rf, average='weighted'),\n",
        "    'Recall': recall_score(y_test, y_pred_rf, average='weighted'),\n",
        "    'F1 Score': f1_score(y_test, y_pred_rf, average='weighted')\n",
        "}\n",
        "\n",
        "print(classification_report(y_test, y_pred_rf))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WPdnldnZGmIp"
      },
      "outputs": [],
      "source": [
        "# 4. SUPPORT VECTOR MACHINE (SVM)\n",
        "print(\"\\n4. Support Vector Machine (SVM)\")\n",
        "print(\"-\"*40)\n",
        "svm = SVC(kernel='rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "\n",
        "classification_results['SVM'] = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_svm),\n",
        "    'Precision': precision_score(y_test, y_pred_svm, average='weighted'),\n",
        "    'Recall': recall_score(y_test, y_pred_svm, average='weighted'),\n",
        "    'F1 Score': f1_score(y_test, y_pred_svm, average='weighted')\n",
        "}\n",
        "\n",
        "print(classification_report(y_test, y_pred_svm))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PIs_rIqgGo-P"
      },
      "outputs": [],
      "source": [
        "# 5. K-NEAREST NEIGHBORS (KNN)\n",
        "print(\"\\n5. K-Nearest Neighbors\")\n",
        "print(\"-\"*40)\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "\n",
        "classification_results['KNN'] = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_knn),\n",
        "    'Precision': precision_score(y_test, y_pred_knn, average='weighted'),\n",
        "    'Recall': recall_score(y_test, y_pred_knn, average='weighted'),\n",
        "    'F1 Score': f1_score(y_test, y_pred_knn, average='weighted')\n",
        "}\n",
        "\n",
        "print(classification_report(y_test, y_pred_knn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PJ2__7y7Ha3v"
      },
      "outputs": [],
      "source": [
        "# 6. NAIVE BAYES\n",
        "print(\"\\n6. Naive Bayes Classifier\")\n",
        "print(\"-\"*40)\n",
        "nb = GaussianNB()\n",
        "nb.fit(X_train, y_train)\n",
        "y_pred_nb = nb.predict(X_test)\n",
        "\n",
        "classification_results['Naive Bayes'] = {\n",
        "    'Accuracy': accuracy_score(y_test, y_pred_nb),\n",
        "    'Precision': precision_score(y_test, y_pred_nb, average='weighted'),\n",
        "    'Recall': recall_score(y_test, y_pred_nb, average='weighted'),\n",
        "    'F1 Score': f1_score(y_test, y_pred_nb, average='weighted')\n",
        "}\n",
        "\n",
        "print(classification_report(y_test, y_pred_nb))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgTykxI9Hd5S"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# SECTION 6: MODEL COMPARISON\n",
        "# ===================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 6: MODEL COMPARISON & RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nCLASSIFICATION MODELS COMPARISON\")\n",
        "print(\"-\"*80)\n",
        "class_df = pd.DataFrame(classification_results).T\n",
        "class_df = class_df.round(4)\n",
        "print(class_df.to_string())\n",
        "\n",
        "print(\"\\nüèÜ BEST CLASSIFICATION MODEL:\")\n",
        "best_clf_model = class_df['Accuracy'].idxmax()\n",
        "print(class_df[class_df['Accuracy'] == class_df['Accuracy'].max()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5zAhiyvIkdb"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# SECTION 7: VISUALIZATIONS\n",
        "# ===================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 7: GENERATING COMPARISON VISUALIZATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Classification Models Performance Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "axes[0, 0].barh(class_df.index, class_df['Accuracy'], color='steelblue')\n",
        "axes[0, 0].set_xlabel('Accuracy')\n",
        "axes[0, 0].set_title('Accuracy Comparison')\n",
        "\n",
        "axes[0, 1].barh(class_df.index, class_df['Precision'], color='coral')\n",
        "axes[0, 1].set_xlabel('Precision')\n",
        "axes[0, 1].set_title('Precision Comparison')\n",
        "\n",
        "axes[1, 0].barh(class_df.index, class_df['Recall'], color='mediumseagreen')\n",
        "axes[1, 0].set_xlabel('Recall')\n",
        "axes[1, 0].set_title('Recall Comparison')\n",
        "\n",
        "axes[1, 1].barh(class_df.index, class_df['F1 Score'], color='mediumpurple')\n",
        "axes[1, 1].set_xlabel('F1 Score')\n",
        "axes[1, 1].set_title('F1 Score Comparison')\n",
        "\n",
        "for ax in axes.flat:\n",
        "    ax.grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úì Visualizations generated successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# Confusion Matrices for All Classification Models\n",
        "# ===================================================\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Get predictions from all classification models\n",
        "# You need to store these predictions when training each model\n",
        "classification_predictions = {\n",
        "    'Logistic Regression': y_pred_lr,\n",
        "    'Decision Tree': y_pred_dt,\n",
        "    'Random Forest': y_pred_rf,\n",
        "    'SVM': y_pred_svm,\n",
        "    'KNN': y_pred_knn,\n",
        "    'Naive Bayes': y_pred_nb\n",
        "}\n",
        "\n",
        "# Create figure with subplots for each model\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "# Get unique class labels\n",
        "class_labels = sorted(y_test.unique())\n",
        "\n",
        "for idx, (model_name, y_pred) in enumerate(classification_predictions.items()):\n",
        "    # Calculate confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=class_labels)\n",
        "\n",
        "    # Calculate percentages\n",
        "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
        "\n",
        "    # Create annotations with both count and percentage\n",
        "    annotations = []\n",
        "    for i in range(cm.shape[0]):\n",
        "        row = []\n",
        "        for j in range(cm.shape[1]):\n",
        "            count = cm[i, j]\n",
        "            percent = cm_percent[i, j]\n",
        "            row.append(f'{count}\\n({percent:.1f}%)')\n",
        "        annotations.append(row)\n",
        "\n",
        "    # Plot heatmap\n",
        "    sns.heatmap(cm, annot=annotations, fmt='', cmap='Blues',\n",
        "                xticklabels=class_labels, yticklabels=class_labels,\n",
        "                ax=axes[idx], cbar_kws={'label': 'Count'},\n",
        "                linewidths=2, linecolor='white')\n",
        "\n",
        "    # Add accuracy to title\n",
        "    accuracy = classification_results[model_name]['Accuracy']\n",
        "    axes[idx].set_title(f'{model_name}\\nAccuracy: {accuracy:.4f}',\n",
        "                       fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_ylabel('Actual', fontsize=10, fontweight='bold')\n",
        "    axes[idx].set_xlabel('Predicted', fontsize=10, fontweight='bold')\n",
        "\n",
        "    # Highlight diagonal (correct predictions) with thicker border\n",
        "    for i in range(len(class_labels)):\n",
        "        axes[idx].add_patch(plt.Rectangle((i, i), 1, 1, fill=False,\n",
        "                                         edgecolor='green', lw=3))\n",
        "\n",
        "plt.suptitle('üéØ CONFUSION MATRICES: All Classification Models',\n",
        "             fontsize=16, fontweight='bold', y=0.995)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Confusion Matrices for All Models Generated!\")\n",
        "\n",
        "# Print interpretation guide\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä HOW TO READ CONFUSION MATRICES:\")\n",
        "print(\"=\"*80)\n",
        "print(\"‚Ä¢ Diagonal (green boxes) = CORRECT predictions\")\n",
        "print(\"‚Ä¢ Off-diagonal = INCORRECT predictions\")\n",
        "print(\"‚Ä¢ Darker colors = More predictions\")\n",
        "print(\"‚Ä¢ Format: Count (Percentage of actual class)\")\n",
        "print(\"\\nExample interpretation:\")\n",
        "print(\"  If cell [Drug A, Drug B] = 5 (10%)\")\n",
        "print(\"  ‚Üí 5 instances of actual Drug A were incorrectly predicted as Drug B\")\n",
        "print(\"  ‚Üí This represents 10% of all actual Drug A cases\")\n",
        "print(\"=\"*80)\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
