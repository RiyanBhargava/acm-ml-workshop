{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uiPblYMH17iu"
      },
      "source": [
        "# ML WORSHOP DAY 2 : MODEL TRAINING AND ANALYSIS\n",
        "### **Objectives :**\n",
        "- Understand train test split\n",
        "- Understand various regression models : Linear, Decision Tree, Random Forest, KNN, SVM, Naive Bayes\n",
        "- Evaluate and compare performance of model based on various evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hrVJs6280wE4"
      },
      "outputs": [],
      "source": [
        "#Importing the necessary libraries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqoPOOPp7sO8"
      },
      "outputs": [],
      "source": [
        "#Importing the required models\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DB9O3pdc2yYE"
      },
      "outputs": [],
      "source": [
        "#To import the pre processed dataset\n",
        "\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6biAryK3A1e"
      },
      "outputs": [],
      "source": [
        "#Loading the preprocessed dataset into a pandas dataframe\n",
        "df = pd.read_csv('preprocessed_data.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1uUGjj676Wb"
      },
      "source": [
        "Now in our dataset, price is the target i.e. what we are predicting.  \n",
        "So we will seperate price column from the other columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tV9F-vxptoNg"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JI4A7Qkh8--1"
      },
      "outputs": [],
      "source": [
        "#Dropping the size column as it is a text based column and not required because we have already extracted the numerical features from it\n",
        "df1=df.drop(['size'],axis='columns')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynonEUDi7O8c"
      },
      "outputs": [],
      "source": [
        "# Features: drop 'price' (target), keep all others\n",
        "feature_cols = [col for col in df1.columns if col != 'price']\n",
        "X = df1[feature_cols]\n",
        "y = df1['price']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZocXwAY8GSQ"
      },
      "outputs": [],
      "source": [
        "print(f\"‚úì Feature matrix shape: {X.shape}\")\n",
        "print(f\"‚úì Target (price) shape: {y.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsAbe4eT8OAF"
      },
      "source": [
        "Performing train test split - to split our dataset into training and testing values.  \n",
        "Training values - the values that our model will learn and understand  \n",
        "Testing values - the values that our model will predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCNcfGFO8KA3"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxZHohGD-7-F"
      },
      "outputs": [],
      "source": [
        "#We will store the results of regression into this dictionary\n",
        "regression_results = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RK9PBhnv-rpx"
      },
      "outputs": [],
      "source": [
        "# 1. LINEAR REGRESSION\n",
        "print(\"\\n1. Linear Regression\")\n",
        "print(\"-\"*40)\n",
        "lr = LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "\n",
        "mse_lr = mean_squared_error(y_test, y_pred_lr)\n",
        "rmse_lr = np.sqrt(mse_lr)\n",
        "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
        "r2_lr = r2_score(y_test, y_pred_lr)\n",
        "\n",
        "regression_results['Linear Regression'] = {\n",
        "    'MSE': mse_lr, 'RMSE': rmse_lr, 'MAE': mae_lr, 'R¬≤ Score': r2_lr\n",
        "}\n",
        "\n",
        "print(f\"  Mean Squared Error: {mse_lr:.4f}\")\n",
        "print(f\"  Root Mean Squared Error: {rmse_lr:.4f}\")\n",
        "print(f\"  Mean Absolute Error: {mae_lr:.4f}\")\n",
        "print(f\"  R¬≤ Score: {r2_lr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9SKMLwzE_R52"
      },
      "outputs": [],
      "source": [
        "# 2. DECISION TREE REGRESSOR\n",
        "print(\"\\n2. Decision Tree Regressor\")\n",
        "print(\"-\"*40)\n",
        "dtr = DecisionTreeRegressor(random_state=42, max_depth=10)\n",
        "dtr.fit(X_train, y_train)\n",
        "y_pred_dtr = dtr.predict(X_test)\n",
        "\n",
        "mse_dtr = mean_squared_error(y_test, y_pred_dtr)\n",
        "rmse_dtr = np.sqrt(mse_dtr)\n",
        "mae_dtr = mean_absolute_error(y_test, y_pred_dtr)\n",
        "r2_dtr = r2_score(y_test, y_pred_dtr)\n",
        "\n",
        "regression_results['Decision Tree'] = {\n",
        "    'MSE': mse_dtr, 'RMSE': rmse_dtr, 'MAE': mae_dtr, 'R¬≤ Score': r2_dtr\n",
        "}\n",
        "\n",
        "print(f\"  Mean Squared Error: {mse_dtr:.4f}\")\n",
        "print(f\"  Root Mean Squared Error: {rmse_dtr:.4f}\")\n",
        "print(f\"  Mean Absolute Error: {mae_dtr:.4f}\")\n",
        "print(f\"  R¬≤ Score: {r2_dtr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "As1z7vQy_cXB"
      },
      "outputs": [],
      "source": [
        "# 3. RANDOM FOREST REGRESSOR\n",
        "print(\"\\n3. Random Forest Regressor\")\n",
        "print(\"-\"*40)\n",
        "rfr = RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10)\n",
        "rfr.fit(X_train, y_train)\n",
        "y_pred_rfr = rfr.predict(X_test)\n",
        "\n",
        "mse_rfr = mean_squared_error(y_test, y_pred_rfr)\n",
        "rmse_rfr = np.sqrt(mse_rfr)\n",
        "mae_rfr = mean_absolute_error(y_test, y_pred_rfr)\n",
        "r2_rfr = r2_score(y_test, y_pred_rfr)\n",
        "\n",
        "regression_results['Random Forest'] = {\n",
        "    'MSE': mse_rfr, 'RMSE': rmse_rfr, 'MAE': mae_rfr, 'R¬≤ Score': r2_rfr\n",
        "}\n",
        "\n",
        "print(f\"  Mean Squared Error: {mse_rfr:.4f}\")\n",
        "print(f\"  Root Mean Squared Error: {rmse_rfr:.4f}\")\n",
        "print(f\"  Mean Absolute Error: {mae_rfr:.4f}\")\n",
        "print(f\"  R¬≤ Score: {r2_rfr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rv2g-pSq_i0q"
      },
      "outputs": [],
      "source": [
        "# 4. SUPPORT VECTOR REGRESSOR (SVR)\n",
        "print(\"\\n4. Support Vector Regressor (SVR)\")\n",
        "print(\"-\"*40)\n",
        "svr = SVR(kernel='rbf')\n",
        "svr.fit(X_train, y_train)\n",
        "y_pred_svr = svr.predict(X_test)\n",
        "\n",
        "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
        "rmse_svr = np.sqrt(mse_svr)\n",
        "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
        "r2_svr = r2_score(y_test, y_pred_svr)\n",
        "\n",
        "regression_results['SVR'] = {\n",
        "    'MSE': mse_svr, 'RMSE': rmse_svr, 'MAE': mae_svr, 'R¬≤ Score': r2_svr\n",
        "}\n",
        "\n",
        "print(f\"  Mean Squared Error: {mse_svr:.4f}\")\n",
        "print(f\"  Root Mean Squared Error: {rmse_svr:.4f}\")\n",
        "print(f\"  Mean Absolute Error: {mae_svr:.4f}\")\n",
        "print(f\"  R¬≤ Score: {r2_svr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz1rR7DF_6nL"
      },
      "outputs": [],
      "source": [
        "# 5. K-NEAREST NEIGHBORS REGRESSOR\n",
        "print(\"\\n5. K-Nearest Neighbors Regressor\")\n",
        "print(\"-\"*40)\n",
        "knr = KNeighborsRegressor(n_neighbors=5)\n",
        "knr.fit(X_train, y_train)\n",
        "y_pred_knr = knr.predict(X_test)\n",
        "\n",
        "mse_knr = mean_squared_error(y_test, y_pred_knr)\n",
        "rmse_knr = np.sqrt(mse_knr)\n",
        "mae_knr = mean_absolute_error(y_test, y_pred_knr)\n",
        "r2_knr = r2_score(y_test, y_pred_knr)\n",
        "\n",
        "regression_results['KNN'] = {\n",
        "    'MSE': mse_knr, 'RMSE': rmse_knr, 'MAE': mae_knr, 'R¬≤ Score': r2_knr\n",
        "}\n",
        "\n",
        "print(f\"  Mean Squared Error: {mse_knr:.4f}\")\n",
        "print(f\"  Root Mean Squared Error: {rmse_knr:.4f}\")\n",
        "print(f\"  Mean Absolute Error: {mae_knr:.4f}\")\n",
        "print(f\"  R¬≤ Score: {r2_knr:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rNeJkCxAQ6-"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# SECTION 6: MODEL COMPARISON\n",
        "# ===================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 6: MODEL COMPARISON & RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nREGRESSION MODELS COMPARISON\")\n",
        "print(\"-\"*80)\n",
        "reg_df = pd.DataFrame(regression_results).T\n",
        "reg_df = reg_df.round(4)\n",
        "print(reg_df.to_string())\n",
        "\n",
        "print(\"\\nüèÜ BEST REGRESSION MODEL:\")\n",
        "best_reg_model = reg_df['R¬≤ Score'].idxmax()\n",
        "print(f\"  {best_reg_model} with R¬≤ Score of {reg_df.loc[best_reg_model, 'R¬≤ Score']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJ47tJ5RG_vr"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# SECTION 7: VISUALIZATIONS\n",
        "# ===================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 7: GENERATING COMPARISON VISUALIZATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "fig.suptitle('Regression Models Performance Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "axes[0, 0].barh(reg_df.index, reg_df['R¬≤ Score'], color='steelblue')\n",
        "axes[0, 0].set_xlabel('R¬≤ Score')\n",
        "axes[0, 0].set_title('R¬≤ Score Comparison')\n",
        "axes[0, 0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "axes[0, 1].barh(reg_df.index, reg_df['RMSE'], color='coral')\n",
        "axes[0, 1].set_xlabel('RMSE (lower is better)')\n",
        "axes[0, 1].set_title('RMSE Comparison')\n",
        "axes[0, 1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "axes[1, 0].barh(reg_df.index, reg_df['MAE'], color='mediumseagreen')\n",
        "axes[1, 0].set_xlabel('MAE (lower is better)')\n",
        "axes[1, 0].set_title('MAE Comparison')\n",
        "axes[1, 0].grid(axis='x', alpha=0.3)\n",
        "\n",
        "axes[1, 1].barh(reg_df.index, reg_df['MSE'], color='mediumpurple')\n",
        "axes[1, 1].set_xlabel('MSE (lower is better)')\n",
        "axes[1, 1].set_title('MSE Comparison')\n",
        "axes[1, 1].grid(axis='x', alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úì Visualizations generated successfully!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSlAUVMQHW3h"
      },
      "outputs": [],
      "source": [
        "# ===================================================\n",
        "# SECTION 8: KEY INSIGHTS & RECOMMENDATIONS\n",
        "# ===================================================\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SECTION 8: KEY INSIGHTS & RECOMMENDATIONS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüìä REGRESSION ANALYSIS:\")\n",
        "print(f\"  ‚Ä¢ Best Model: {best_reg_model}\")\n",
        "print(f\"  ‚Ä¢ R¬≤ Score: {reg_df.loc[best_reg_model, 'R¬≤ Score']:.4f}\")\n",
        "print(f\"  ‚Ä¢ This model explains {reg_df.loc[best_reg_model, 'R¬≤ Score']*100:.2f}% of variance in house prices\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}